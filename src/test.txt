import React, { useState, useRef, useEffect } from "react";
import { FaMicrophone } from "react-icons/fa";
import { FaRegCirclePause } from "react-icons/fa6";
import { IoSend } from "react-icons/io5";

export default function App() {
  const [mediaRecorder, setMediaRecorder] = useState(null);
  const [isRecording, setIsRecording] = useState(false);
  const [audioBlobs, setAudioBlobs] = useState([]);
  const [recordedAudioURL, setRecordedAudioURL] = useState(null); // Track paused audio URL
  const audioRef = useRef(null);
  const audioContext = useRef(null);
  const audioStream = useRef(null);
  const [startTime, setStartTime] = useState(null); // Track recording start time
  const [totalTime, setTotalTime] = useState(0); // Track total paused time
  const [elapsedTime, setElapsedTime] = useState(0); // Track elapsed recording time
  const intervalRef = useRef(null); // Reference for the interval

  useEffect(() => {
    audioContext.current = new AudioContext();
  }, []);

  useEffect(() => {
    if (isRecording) {
      intervalRef.current = setInterval(() => {
        setElapsedTime((prevElapsedTime) => prevElapsedTime + 1);
      }, 1000);
    } else {
      clearInterval(intervalRef.current);
    }
    return () => clearInterval(intervalRef.current);
  }, [isRecording]);

  useEffect(() => {
    if (audioBlobs.length > 0) {
      // Fallback: Play the entire recording if no paused audio available
      const audioBlob = new Blob(audioBlobs, { type: "audio/webm" });
      const url = URL.createObjectURL(audioBlob);
      audioRef.current.src = url;
    }
  }, [audioBlobs]);
  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorderInstance = new MediaRecorder(stream);
      setMediaRecorder(mediaRecorderInstance);
      audioStream.current = stream;

      mediaRecorderInstance.addEventListener("dataavailable", (event) => {
        // console.log(
        //   "ðŸš€ ~ mediaRecorderInstance.addEventListener ~ event:",
        //   event
        // );
        if (event.data.size > 0) {
          setAudioBlobs((prevBlobs) => [...prevBlobs, event.data]);
        }
      });
      mediaRecorderInstance.addEventListener("pause", (event) => {
        // console.log(
        //   "ðŸš€ ~ mediaRecorderInstance.addEventListener ~ event:",
        //   event
        // );
      });
      setStartTime(Date.now());
      mediaRecorderInstance.addEventListener("start", (event) => {});

      mediaRecorderInstance.start();
      setIsRecording(true);
    } catch (error) {
      console.error("Error starting recording:", error);
    }
  };

  const pauseRecording = () => {
    if (mediaRecorder && isRecording) {
      let timeInSeconds = (Date.now() - startTime) / 1000;

      setTotalTime((prev) => prev + timeInSeconds);
      mediaRecorder.pause();
      setIsRecording(false);
      mediaRecorder.requestData();

      if (audioBlobs.length > 0) {
        // Fallback: Play the entire recording if no paused audio available
        const audioBlob = new Blob(audioBlobs, { type: "audio/webm" });
        const url = URL.createObjectURL(audioBlob);
        audioRef.current.src = url;
      }
      // Create a Blob from the accumulated audioBlobs for immediate playback
      // const recordedBlob = new Blob(audioBlobs, { type: 'audio/webm' });
      // const url = URL.createObjectURL(recordedBlob);
      // setRecordedAudioURL(url); // Update paused audio URL
    }
  };

  const resumeRecording = () => {
    if (mediaRecorder && !isRecording) {
      setStartTime(Date.now());

      mediaRecorder.resume();
      setIsRecording(true);
      setRecordedAudioURL(null); // Clear paused audio URL when resuming recording
    }
  };

  const stopRecording = () => {
    console.log("is audio recording ", isRecording);
    if (mediaRecorder && isRecording) {
      mediaRecorder.stop();
      setIsRecording(false);
      audioContext.current.close();
      setRecordedAudioURL(null);

      if (audioBlobs.length > 0) {
        const audioBlob = new Blob(audioBlobs, { type: "audio/webm" });
        const audioURL = window.URL.createObjectURL(audioBlob);

        // Create a download link and click it programmatically
        const anchor = document.createElement("a");
        anchor.href = audioURL;
        anchor.download = "recorded_audio.webm";
        document.body.appendChild(anchor);
        anchor.click();
        document.body.removeChild(anchor);
        window.URL.revokeObjectURL(audioURL);

        // Reset the audioBlobs
        setAudioBlobs([]);
      }
    }

    if (audioBlobs.length > 0) {
      const audioBlob = new Blob(audioBlobs, { type: "audio/webm" });
      const audioURL = window.URL.createObjectURL(audioBlob);

      // Create a download link and click it programmatically
      const anchor = document.createElement("a");
      anchor.href = audioURL;
      anchor.download = "recorded_audio.webm";
      document.body.appendChild(anchor);
      anchor.click();
      document.body.removeChild(anchor);
      window.URL.revokeObjectURL(audioURL);

      // Reset the audioBlobs
      setAudioBlobs([]);
    }
  };

  const playAudio = () => {
    if (recordedAudioURL) {
      audioRef.current.src = recordedAudioURL;
      audioRef.current.play();
    } else if (audioBlobs.length > 0) {
      // Fallback: Play the entire recording if no paused audio available
      const audioBlob = new Blob(audioBlobs, { type: "audio/webm" });
      const url = URL.createObjectURL(audioBlob);
      audioRef.current.src = url;
      audioRef.current.play();
    }
  };

  const formatTime = (seconds) => {
    const minutes = Math.floor(seconds / 60);
    const remainingSeconds = seconds % 60;
    return `${minutes}:${remainingSeconds < 10 ? "0" : ""}${remainingSeconds}`;
  };

  return (
    <div className="m-[30px]">
      <div className={`audio-track ${isRecording ? "recording" : ""}`}>
        <div className="flex space-x-[5px] items-center">
          {isRecording ? (
            <div className="flex items-center">
              <h2>{formatTime(elapsedTime)}</h2>
              <img src="/sound.gif" className="w-[120px] h-[35px]" />
            </div>
          ) : audioBlobs.length > 0 ? (
            <audio ref={audioRef} controls />
          ) : (
            ""
          )}

          {!isRecording && (
            <button
              onClick={() => {
                if (audioBlobs.length > 0) {
                  resumeRecording();
                } else {
                  startRecording();
                }
              }}
            >
              {" "}
              <FaMicrophone className="text-[25px] text-[red]" />{" "}
            </button>
          )}
          {isRecording ? (
            <button onClick={pauseRecording}>
              <FaRegCirclePause className="text-[20px] text-[red]" />
            </button>
          ) : (
            ""
            // <button onClick={resumeRecording}>Resume Recording</button>
          )}
          <button
            onClick={stopRecording}
            className="p-[11px] rounded-full bg-[#2ea75a] text-[white]"
          >
            <IoSend />
          </button>
        </div>
        {/* {audioBlobs.length > 0 && (
          <button onClick={playAudio}>
            Play {recordedAudioURL ? "Paused Audio" : "Recorded Audio"}
          </button>
        )} */}
      </div>
    </div>
  );
}
